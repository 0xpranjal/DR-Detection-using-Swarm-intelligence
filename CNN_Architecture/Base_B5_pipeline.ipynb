{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport cv2,glob,time, random\nimport warnings\n\nfrom tqdm import tqdm \n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import StepLR,ReduceLROnPlateau\nfrom torch.optim import Adam\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n!pip install timm \nimport timm\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T08:09:07.902022Z","iopub.execute_input":"2021-06-27T08:09:07.902463Z","iopub.status.idle":"2021-06-27T08:09:23.029239Z","shell.execute_reply.started":"2021-06-27T08:09:07.902370Z","shell.execute_reply":"2021-06-27T08:09:23.027891Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.4.9-py3-none-any.whl (346 kB)\n\u001b[K     |████████████████████████████████| 346 kB 876 kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.4.9\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"MODEL_ARCH= \"efficientnet_b5\"\nEPOCHS = 5\nIMG_SIZE = 512\nBATCH_SIZE = 8\nVAL_BATCH_SIZE = 16\nITER_FREQ = 200\nNUM_WORKERS = 8\nSEED = 42\nMAX_NORM = 1000\nITERS_TO_ACCUMULATE = 1\nSCHEDULER_UPDATE ='epoch' #Can be on a 'batch' basis as well\n\n# Set optimizer, loss and schedulers here later on \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nDEBUG = True # Set this as true when there is a need to test run the whole thing","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.032173Z","iopub.execute_input":"2021-06-27T08:09:23.032636Z","iopub.status.idle":"2021-06-27T08:09:23.088960Z","shell.execute_reply.started":"2021-06-27T08:09:23.032585Z","shell.execute_reply":"2021-06-27T08:09:23.087083Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Plan of action:\n* Pretrain models on 2015 dataset and then train on 2019 dataset\n* The number of epochs used is yet to be decided\n* As of now thinking of K-Fold Validation\n    * Basically, the model would train as it is on 2015 dataset\n    * On the 2019 dataset, folds would be used to check for accuracy ","metadata":{}},{"cell_type":"code","source":"df_2015 = pd.read_csv(\"../input/resized-2015-2019-blindness-detection-images/labels/trainLabels15.csv\")\ndf_2015['level'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.092140Z","iopub.execute_input":"2021-06-27T08:09:23.093090Z","iopub.status.idle":"2021-06-27T08:09:23.174761Z","shell.execute_reply.started":"2021-06-27T08:09:23.093040Z","shell.execute_reply":"2021-06-27T08:09:23.173749Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    25810\n2     5292\n1     2443\n3      873\n4      708\nName: level, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\ndef prepare_labels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n\n    y = onehot_encoded\n    return y, label_encoder","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.176796Z","iopub.execute_input":"2021-06-27T08:09:23.177369Z","iopub.status.idle":"2021-06-27T08:09:23.185247Z","shell.execute_reply.started":"2021-06-27T08:09:23.177273Z","shell.execute_reply":"2021-06-27T08:09:23.183427Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\nif DEBUG:\n    df = df_2015.sample(200).reset_index(drop = True)\nelse:\n    df = df_2015.sample(frac= 1.0,random_state=10).reset_index(drop = True)\ny, le = prepare_labels(df['level'])\nX = df['image'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:21:25.345265Z","iopub.execute_input":"2021-06-27T08:21:25.345725Z","iopub.status.idle":"2021-06-27T08:21:25.365286Z","shell.execute_reply.started":"2021-06-27T08:21:25.345691Z","shell.execute_reply":"2021-06-27T08:21:25.360636Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class ","metadata":{}},{"cell_type":"code","source":"class retinopathy2015(Dataset):\n    def __init__(self,X,y,transform=None):\n#         self.df = df\n        self.imageList = X\n        self.transform = None\n        if transform is None:\n            self.transform = A.Compose([\n                                            A.Resize(IMG_SIZE,IMG_SIZE),\n                                            ToTensorV2()\n                                        ])\n        else:\n            self.transform = transforms\n        self.labels = y\n    \n    def __len__(self):\n        return len(self.imageList)\n    \n    def __getitem__(self,idx):\n        file_name = self.imageList[idx]\n        img = cv2.imread(f\"../input/resized-2015-2019-blindness-detection-images/resized train 15/{file_name}.jpg\")\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=img)\n        image = image['image']\n        label = self.labels[idx]\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.205650Z","iopub.execute_input":"2021-06-27T08:09:23.206303Z","iopub.status.idle":"2021-06-27T08:09:23.215459Z","shell.execute_reply.started":"2021-06-27T08:09:23.206256Z","shell.execute_reply":"2021-06-27T08:09:23.213772Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Transforms( TO BE DEFINED HERE) ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):#EFFNET\n    def __init__(self,model_name,num_classes,pretrained = True):\n        super().__init__()\n        self.model = timm.create_model(model_name,pretrained = pretrained )\n        n_features = self.model.classifier.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.classifier = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features,num_classes)\n        \n    def forward(self,x): \n        bs = x.size(0) # bs -> batch size\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs,-1)\n        output = self.fc(pooled_features)\n        return output ","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.217425Z","iopub.execute_input":"2021-06-27T08:09:23.217907Z","iopub.status.idle":"2021-06-27T08:09:23.230968Z","shell.execute_reply.started":"2021-06-27T08:09:23.217863Z","shell.execute_reply":"2021-06-27T08:09:23.229883Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# model = Model('efficientnet_b5',num_classes = 5, pretrained = True)\n# model.to(device)\n# optimizer = torch.optim.Adam(params, lr=0.001)\n# criterion = nn.BCEWithLogitsLoss().to(device)    \n# scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.234415Z","iopub.execute_input":"2021-06-27T08:09:23.234887Z","iopub.status.idle":"2021-06-27T08:09:23.243499Z","shell.execute_reply.started":"2021-06-27T08:09:23.234841Z","shell.execute_reply":"2021-06-27T08:09:23.242173Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Train and Valid functions","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):    \n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.val = 0\n        self.sum = 0\n        self.avg = 0\n        self.count = 0\n        \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val*n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(SEED)\n\ndef macro_multilabel_auc(label, pred):\n    aucs = []\n    target_cols = [0,1,2,3,4]\n    for i in range(len(target_cols)):\n        aucs.append(roc_auc_score(label[:, i], pred[:, i]))\n#     print(np.round(aucs, 4))\n    return np.mean(aucs)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:20:37.275938Z","iopub.execute_input":"2021-06-27T08:20:37.276453Z","iopub.status.idle":"2021-06-27T08:20:37.289910Z","shell.execute_reply.started":"2021-06-27T08:20:37.276418Z","shell.execute_reply":"2021-06-27T08:20:37.288122Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_fn(model, dataloader, device, epoch, optimizer, criterion, scheduler):\n    \n    data_time = AverageMeter()\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    accuracies = AverageMeter()\n    model.train()\n    scaler = GradScaler()\n    start_time = time.time()\n    loader = tqdm(dataloader, total=len(dataloader))\n    for step, (images, labels) in enumerate(loader):\n        \n        images = images.to(device).float()\n        labels = labels.to(device)\n        data_time.update(time.time() - start_time)\n\n        with autocast():\n            output = model(images)\n            loss = criterion(output, labels)\n            losses.update(loss.item(), BATCH_SIZE)\n            scaler.scale(loss).backward()\n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm = MAX_NORM)\n            if (step+1) % ITERS_TO_ACCUMULATE == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        \n        if scheduler is not None and SCHEDULER_UPDATE == 'batch':\n            scheduler.step()\n\n        batch_time.update(time.time() - start_time)\n        start_time = time.time()\n        \n        if step % ITER_FREQ == 0:\n            \n            print('Epoch: [{0}][{1}/{2}]\\t'\n                  'Batch Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t'\n                  'Data Time {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t'\n                  'Loss: {loss.val:.4f} ({loss.avg:.4f})'.format((epoch+1),\n                                                                    step, len(dataloader),\n                                                                    batch_time=batch_time,\n                                                                    data_time=data_time,\n                                                                    loss=losses))\n                                                                             #accuracy=accuracies))\n        # To check the loss real-time while iterating over data.   'Accuracy {accuracy.val:.4f} ({accuracy.avg:.4f})'\n        loader.set_description(f'Training Epoch {epoch+1}/{EPOCHS}')\n        loader.set_postfix(loss=losses.avg) #accuracy=accuracies.avg)\n#         del images, labels\n#     if scheduler is not None and SCHEDULER_UPDATE == 'epoch':\n#         scheduler.step(losses.avg)\n        \n    return losses.avg","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:09:23.264021Z","iopub.execute_input":"2021-06-27T08:09:23.264923Z","iopub.status.idle":"2021-06-27T08:09:23.280933Z","shell.execute_reply.started":"2021-06-27T08:09:23.264882Z","shell.execute_reply":"2021-06-27T08:09:23.279702Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def valid_fn(epoch, model, criterion, val_loader, device, scheduler):\n    \n    model.eval()\n    losses = AverageMeter()\n    accuracies = AverageMeter()\n    PREDS = []\n    TARGETS = []\n    loader = tqdm(val_loader, total=len(val_loader))\n    with torch.no_grad():  # without torch.no_grad() will make the CUDA run OOM.\n        for step, (images, labels) in enumerate(loader):\n        \n            images = images.float().to(device)\n            labels = labels.to(device)\n            \n            output = model(images)\n            loss = criterion(output, labels)\n            losses.update(loss.item(), VAL_BATCH_SIZE)\n            PREDS += [output.sigmoid()]\n            TARGETS += [labels.detach().cpu()]\n            loader.set_description(f'Validating Epoch {epoch+1}/{EPOCHS}')\n            loader.set_postfix(loss=losses.avg)#, accuracy=accuracies.avg)\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    roc_auc = macro_multilabel_auc(TARGETS, PREDS)\n    if scheduler is not None and SCHEDULER_UPDATE == 'epoch':\n        scheduler.step(losses.avg)\n        \n    return losses.avg, roc_auc","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:18:52.775935Z","iopub.execute_input":"2021-06-27T08:18:52.776335Z","iopub.status.idle":"2021-06-27T08:18:52.787653Z","shell.execute_reply.started":"2021-06-27T08:18:52.776302Z","shell.execute_reply":"2021-06-27T08:18:52.786161Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def engine(device, X_train,X_val,y_train,y_val):\n\n    train_data = retinopathy2015(X_train,y_train, transform=None)\n    val_data = retinopathy2015(X_val, y_val, transform=None)        \n    \n    train_loader = DataLoader(train_data,\n                              batch_size=BATCH_SIZE, \n                              shuffle=True, \n                              num_workers=NUM_WORKERS,\n                              pin_memory=True, # enables faster data transfer to CUDA-enabled GPUs.\n                              drop_last=True)\n    val_loader = DataLoader(val_data,\n                            batch_size=VAL_BATCH_SIZE,\n                            num_workers=NUM_WORKERS,\n                            shuffle=False, \n                            pin_memory=True,\n                            drop_last=False)\n\n    model = Model('efficientnet_b5',num_classes = 5, pretrained = True)\n\n    model.to(device)\n    \n    params = filter(lambda p: p.requires_grad, model.parameters())    \n    optimizer = torch.optim.Adam(params, lr=0.001)\n\n\n    criterion = nn.BCEWithLogitsLoss().to(device)    \n    val_criterion = nn.BCEWithLogitsLoss().to(device)\n\n    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n    scheduler = ReduceLROnPlateau(optimizer, factor=0.8, patience=2)\n    loss = []\n    accuracy = []\n    START_EPOCH = 0\n    for epoch in range(START_EPOCH, EPOCHS):\n        \n        epoch_start = time.time()        \n        avg_loss = train_fn(model, train_loader, device, epoch, optimizer, criterion, scheduler)\n\n        torch.cuda.empty_cache()\n        avg_val_loss, roc_auc_score = valid_fn(epoch, model, val_criterion, val_loader, device, scheduler)\n        epoch_end = time.time() - epoch_start\n        \n        print(f'Validation accuracy after epoch {epoch+1}: {roc_auc_score:.4f}')\n        loss.append(avg_loss)\n        \n        content = f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} roc_auc_score: {roc_auc_score:.4f} time: {epoch_end:.0f}s'\n        with open(f'GPU_{MODEL_ARCH}.txt', 'a') as appender:\n            appender.write(content + '\\n')                                         # avg_train_accuracy: {avg_accuracy:.4f}\n        \n        torch.save(model.state_dict(), f'{MODEL_ARCH}_epoch_{(epoch+1)}.pth')\n        torch.cuda.empty_cache()\n    \n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:22:40.921119Z","iopub.execute_input":"2021-06-27T08:22:40.921502Z","iopub.status.idle":"2021-06-27T08:22:40.936495Z","shell.execute_reply.started":"2021-06-27T08:22:40.921459Z","shell.execute_reply":"2021-06-27T08:22:40.934659Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"engine(device, X_train,X_test,y_train,y_test)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T08:22:42.768198Z","iopub.execute_input":"2021-06-27T08:22:42.768664Z","iopub.status.idle":"2021-06-27T08:23:53.747249Z","shell.execute_reply.started":"2021-06-27T08:22:42.768632Z","shell.execute_reply":"2021-06-27T08:23:53.742907Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Training Epoch 1/5:   5%|▌         | 1/20 [00:04<01:26,  4.58s/it, loss=0.665]","output_type":"stream"},{"name":"stdout","text":"Epoch: [1][0/20]\tBatch Time 4.573s (4.573s)\tData Time 1.670s (1.670s)\tLoss: 0.6654 (0.6654)\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 1/5: 100%|██████████| 20/20 [00:39<00:00,  1.98s/it, loss=0.461]\nValidating Epoch 1/5: 100%|██████████| 3/3 [00:01<00:00,  1.60it/s, loss=1.12]\n","output_type":"stream"},{"name":"stdout","text":"Validation accuracy after epoch 1: 0.5046\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/5:   5%|▌         | 1/20 [00:04<01:25,  4.51s/it, loss=0.333]","output_type":"stream"},{"name":"stdout","text":"Epoch: [2][0/20]\tBatch Time 4.506s (4.506s)\tData Time 1.239s (1.239s)\tLoss: 0.3328 (0.3328)\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2/5:  65%|██████▌   | 13/20 [00:28<00:15,  2.16s/it, loss=0.328]Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n    send_bytes(obj)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n    self._send_bytes(m[offset:offset + size])\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n    self._send(header + buf)\n  File \"/opt/conda/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n    n = write(self._handle, buf)\nBrokenPipeError: [Errno 32] Broken pipe\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-e3d6c7bf8aa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-24-03f9bc097a38>\u001b[0m in \u001b[0;36mengine\u001b[0;34m(device, X_train, X_val, y_train, y_val)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mepoch_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-0b248bc12a82>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, dataloader, device, epoch, optimizer, criterion, scheduler)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mgrad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_NORM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mITERS_TO_ACCUMULATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]}]}